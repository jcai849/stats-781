---
title: Free-Response Analytics
author: Jason Cairns
---
```{r}
library(tidyverse)
library(tidytext)
library(lexRankr)
library(textrank)
library(widyr)
```

```{r}
setwd("../data/")
source("data_import.R")
```

```{r}
tokenised_cancer_soc <-
  cancer_soc %>%
  select(sq6a) %>%
  mutate(id = row_number()) %>%
  unnest_tokens(word, sq6a) %>%
  na.omit
```

```{r}
no_stop_cancer_soc <-
  tokenised_cancer_soc %>%
  anti_join(get_stopwords())
```

Find common words
```{r}
no_stop_cancer_soc %>%
  count(word, sort = TRUE)
```

some quick sentiment analysis using NRC. Let's see what NRC has available:

```{r}
get_sentiments("nrc") %>%
  distinct(sentiment)
```

```{r}
nrc_trust <-
  get_sentiments("nrc") %>%
  filter(sentiment == "trust")

no_stop_cancer_soc %>%
  semi_join(nrc_trust) %>%
  count(word, sort = TRUE)
```

Summarisation with lexRank

```{r}
lexRank(cancer_soc$sq6a)
```

Keywords with textrank

```{r}
keyw <-
  textrank_keywords(no_stop_cancer_soc$word)

head(keyw$keywords, 10)
```

Bigrams

```{r}
cancer_soc_bigrams <-
  cancer_soc %>%
  select(sq6a) %>%
  mutate(id = row_number()) %>%
  unnest_tokens(bigram, sq6a, token = "ngrams", n = 2) %>%
  na.omit()

bigrams_separated <- cancer_soc_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

# new bigram counts:
bigram_counts <- bigrams_united %>% 
  count(bigram, sort = TRUE)

bigram_counts
```

tf-idf - this is a measure of the important words within each response, ignoring those
that are common throughout - not so useful in this analysis? too many observations,
but may be useful under small n grouping variables.

```{r}
cancer_soc_words <-
  cancer_soc %>%
  select(sq6a) %>%
  mutate(id = row_number()) %>%
  unnest_tokens(word, sq6a) %>%
  count(id, word, sort = TRUE)

total_words <-
  cancer_soc_words %>%
  group_by(id) %>%
  summarize(total = sum(n))

tf_idf_cancer_soc <-
  left_join(cancer_soc_words, total_words) %>%
  bind_tf_idf(word, id, n)

tf_idf_cancer_soc %>%
  arrange(desc(tf_idf))
```

pairwise correlation

```{r}
word_cors <- tokenised_cancer_soc %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, id, sort = TRUE)

word_cors
```

This is probably far more useful than bigrams.

---

There is still much to be done in between-item analysis. This should also be run on the
nzqhs dataset as well

