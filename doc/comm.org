* 2019-03-06
  :PROPERTIES:
  :CUSTOM_ID: section
  :END:

** Preparation
   :PROPERTIES:
   :CUSTOM_ID: preparation
   :END:

*Question*: How should this dissertation relate to Cassidy's
[[../reading/CassidyStuff/CassidyStuff/Our%20text%20analytics%20project.docx][project
outline]]?

Thoughts on data structures:

- dataframe seems ok for tidy text style data
- nested dataframe may be best for survey response data
- look at other styles (incl. non-tidy), maybe trees, as per parse trees
  etc
- Document-term matrix for tf-idf (PCA would be interesting here due to
  massive dimension)

*Reading*: [[https://www.tidytextmining.com][Text Mining with R]]:
[[../notes/text_mining_with_r.org][notes]]

- [X] Read Text Mining with R
- [X] Assess Twitter api
- [X] Play with iNZight/lite, Cassidy's Project
- [X] Consider UI
- [X] Consider Survey Responses
- [X] Draft UI Depictions

** Minutes / Summary
   :PROPERTIES:
   :CUSTOM_ID: minutes-summary
   :END:

#+BEGIN_QUOTE
  UI is something that will have to be organically developed as we go.
#+END_QUOTE

Meeting was mainly demonstration from Jason to Chris about the
preparation done, as well as Chris demonstrating to Jason the current
iNZight UX. Research so far is good, but too broad to demonstrate in the
confines of a weekly meeting - Chris suggested a [[#actions][solution]];
to set notes in a neat summary format and publish to a github repository

** Actions
   :PROPERTIES:
   :CUSTOM_ID: actions
   :END:

- [X] Set notes in neat summary form (organise file structure to match)
- [X] Push to a private github repository
- [X] Give access to Chris
- [ ] +Create twitter developer account+
- [ ] +Get twitter api access token+

* 2019-03-13
  :PROPERTIES:
  :CUSTOM_ID: section-1
  :END:

** Minutes / Summary
   :PROPERTIES:
   :CUSTOM_ID: minutes-summary-1
   :END:

This meeting took place while seeing what packages exist already to
complete various tasks. We looked though the various packages I have
found. Determined that we needed to reel in and pick specific features
that we want, according to the heuristic; if it isn't obvious
immediately, get rid of it. The primary question we seek to answer with
this text analytics program is, what are people talking about, and how
do they feel about it. With this in mind, analysis for e.g. writing
styles are not to be considered (who wrote shakespeare etc.).


** Actions
- [ ] +interface (w. respect to above)+
- [ ] +lit review of twitter analysis (esp. discourse)+
- [X] Determine what text analysis really is at base, and how it relates
 to the primary question
- [X] find if subtitles can be attained easily enough
- [X] formal critique of Cassidy's project, integration w/ iNZight
- [X] scope reduction
- [X] See similar papers in stats printing room

* 2019-03-20
  :PROPERTIES:
  :CUSTOM_ID: section-2
  :END:

** Summary
   :PROPERTIES:
   :CUSTOM_ID: summary
   :END:

Close assessment of textrank package and background algorithm - on the
right track for scope. Chris noted to check for survey response data
etc. from those involved with it.

** Actions

- [X] Create an example corpus for testing
- [X] Assess textrank performance on the example corpus

* 2019-03-28
  :PROPERTIES:
  :CUSTOM_ID: section-3
  :END:

** Summary
   :PROPERTIES:
   :CUSTOM_ID: summary-1
   :END:

Presentation of further package discoveries, for development purposes,
as well as end-user. Demonstrated the benefits and drawbacks of using
textRank, discussed the possibility of lexRank. Presented draft of
feature space - including the usefulness of categorisation of text
analytics as within- and between- texts. Much discussion dedicated to
summarisation.

** Actions
   :PROPERTIES:
   :CUSTOM_ID: actions-3
   :END:

- [X] Development of a test-corpus; Chris has emailed some free-form
  patient responses
- [X] Further testing of textRank (try tidy-style) on corpus
- [X] Testing lexRank on on test corpus
- [X] Formalise feature-space as list

* 2019-04-03
  :PROPERTIES:
  :CUSTOM_ID: section-4
  :END:

** Summary
   :PROPERTIES:
   :CUSTOM_ID: summary-2
   :END:

Demonstration of summarisation systems, confirmation of use of lexRank,
discussion of case of free-form response data - much interest in these
capabilities

** Actions
   :PROPERTIES:
   :CUSTOM_ID: actions-4
   :END:

- [X] Testing of standard text analysis tools on free-response data - see
  what is useful
- [X] Summarisation of Free responses using the two example datasets;
  indiv. response as token?
- [ ] Test grouping variables such as survey group in the analysis
- [X] LexRank for keywords - Not possible

* CLOSED 2019-04-10
  CLOSED: [2019-04-19 Fri 17:52] SCHEDULED: <2019-04-10 Wed>

- [ ] Look into pairwise_cor function to determine order and remove repetition
- [ ] Complete previous week's tasks
* CLOSED Meeting Chris @his-office
  CLOSED: [2019-04-19 Fri 17:52]
  <2019-04-17 Wed>
* Discussion and tasks
  <2019-04-24 Wed 11:00-12:00>
** Preparation:
- [X] Between-group analytics for free-response data
- [X] Topic Modelling
- [X] Consider grouping variables: Responses within each group is functionally equivalent to analysing chapters in a book, which our methods all provide for
** To Discuss
- [ ] Preparation
- [ ] Conditional analytics
- [ ] Sentiment Distributions
** CLOSED Actions
   CLOSED: [2019-05-04 Sat 15:57] DEADLINE: <2019-05-02 Thu>
Write more on observations as paragraphs for dissertation
*** CLOSED Learn how textrank_keywords works
    CLOSED: [2019-05-03 Fri 10:57] SCHEDULED: <2019-05-03 Fri>
Especially in formatting n-grams, what is "freq" referring to. Figure out what's wrong with bigrams
[[file:further-free-response.org][link]]
*** CLOSED Condition actions, form sentiment distribution
    CLOSED: [2019-04-29 Mon 09:28] SCHEDULED: <2019-04-29 Mon>
[[https://github.com/bnosac/BTM][This]] may be useful
[[file:sent-dist.org][link]]
* Meeting Chris
<2019-05-08 Wed 11:00-12:00>
** Topics
- Prior Actions
- Look into in-text topic modelling
- Implementation in Shiny (timeline) - possibility of python?
- ggpage: see later upon implementation
** CLOSED Schedule Meeting for Thurs/Fri
   CLOSED: [2019-05-02 Thu 16:13] SCHEDULED: <2019-05-03 Fri>
** CLOSED Actions
   CLOSED: [2019-05-17 Fri 09:06] DEADLINE: <2019-05-15 Wed>
- Look into alternative stopword lists and stopwords for different purposes
- Sentiment frequencies of positive and negative words, coloured continuously by their sentiment score. (include even for diagnostic purposes)
- Have a look at a few different displays (e.g. scatterplot of frequency ~ sentiment score).
- Forms of Topic Modelling
*** CLOSED Dissertation Work
    CLOSED: [2019-05-14 Tue 20:22] SCHEDULED: <2019-05-14 Tue>
* Meeting Chris
<2019-05-15 Wed 11:00-12:00>
** Topics
** CLOSED Actions [4/5]
   CLOSED: [2019-05-22 Wed 12:35] SCHEDULED: <2019-05-21 Tue>
- [X] Write on contextual search function
- [X] Write on necessity of temporary stopwords list
  - [X] assess in future if it will be too slow if running in real time
  - [X] good to have a running statistic of what has been done to the data (stopword removal etc.)
- [X] Write on why LDA was chosen and others weren't considered
- [X] Write on ggpage
- [ ] Start building wrapper functions
  - [ ]wrapper function for summarisation
    - [ ]parameters may include different visualisation formats
* Meeting Chris
<2019-05-22 Wed 11:00-12:00>
** Topics
** Action [2/6]
- [X] better name
- [X] novel test set
- [ ] automate processing for each df argument
- [ ] construct word/ngram/keyword wrapper
- [ ] construct sentence wrapper
- [ ] write on a diagram wrapper
* Meeting Chris
<2019-05-29 Wed 11:00-12:00>
** Topics
** CLOSED Actions
   CLOSED: [2019-06-13 Thu 12:44] DEADLINE: <2019-06-12 Wed>
*** Work on Dissertation [2/4]
- [X] Create text import wrapper
- [X] Create stopword removal wrapper
- [ ] Create framework of word-level analytics, create for word frequency
- [ ] Prove the recreation of the original text from the deconstructed text
* Meeting Chris
<2019-06-12 Wed 11:00-12:00>
** Topics
** Actions
* Meeting Chris
<2019-06-19 Wed 11:00-12:00>
** Topics
*** CLOSED Work on Dissertation
    CLOSED: [2019-06-14 Fri 14:14] SCHEDULED: <2019-06-13 Thu>
** Actions
* Meeting Chris
<2019-07-02 Tue 11:00-12:00>
** Topics
*** CLOSED Dissertation
   CLOSED: [2019-07-07 Sun 18:10] SCHEDULED: <2019-06-30 Sun>
- [ ] start on grouping
- [ ] Try make column names of "insight" and "group" columns explicit in the name,
  so that they can be accessed programmatically through a string search

** Actions
- [ ] Work on functions
- [ ] Create more tests, including for free-response
- [ ] Test ggpage, consider how to structure standard object
* Meeting Chris
<2019-07-09 Tue 11:00-12:00>
** Topics
** CLOSED Dissertation Work
   CLOSED: [2019-07-21 Sun 15:25] SCHEDULED: <2019-07-13 Sat 17:30>
   SCHEDULED: <2019-07-16 Tue>
- [X] get_insight functions work on named column rather than "word" as
  default - word may still be the keyword argument
- [X] additional processing functions to add/alter columns around
  insight (e.g. stopwords scans named word column, removes
  corresponding insight entry, lemmatise adds additional lemma column
  to words, in order to have text insight performed on lemma column)
- [X] sentence/group level summary insights
- [ ] Start on latex dissertation formatting
** CLOSED Further Dissertation Work [3/4]
   CLOSED: [2019-07-25 Thu 18:52] SCHEDULED: <2019-07-24 Wed 13:00-16:00>
- [X] Create demonstration
- [X] Send demonstration to Chris
- [ ] Finish last few functions
- [X] Begin shiny study
** Demonstration
Hi Chris,

To summarise the progress since you've been away, I have completed the
import wrapper function, as well as nearly all insight functions,
including some new ones I'm excited to show you in person. In fact,
most of the work has been done on the architecture and the data
structres; The primary data object is now (aside from punctuation,
which I can accept losing) completely lossless, so at any stage (not
that we have to anymore), we can recreate the original text.
Visualisation now includes ggpage, and all of these have been tested
and found to work with grouping and filtering. There are a few more
insight functions to add, but there's no difficulty in them, just a
case of spending time.

Implemented:
- Term Frequency
- Bigram functions
- TextRank Key Words
- Term Sentiment
- Term Count
- LexRank Key Sentences
- Aggregate Sentiment (working on mean, median, sd, etc.)

To be Completed:
- Term Correlation
- Term Frequency - Inverse Document Frequency
- Topic Modelling

There has been a setback however, due to using the =tidytext= package.
After a recent update to the package, there were major breakages in
backwards compatibility, completely changing the output from functions
I was dependent on. I managed to get things working again, but some of
the changes may possibly lead to issues for our package later on - not
sure it's a good idea to keep it as a dependency with those kind of
development practices, but I don't think it's necessarily a good idea
to switch either, given that time is so precious.

I would like to make a wrapper function for insight and visualisation,
however I should get a fair idea of what input and output to expect,
so I was thinking I ought to create a shiny prototype to get me
familiar first. Not sure, what are your thoughts?

I've attached some of the current visualisations for your interest,
all now taken from import to visualisation in only a few lines of code.

I hope you're enjoying your trip.

Kind Regards,
Jason
* Contact Chris
<2019-07-17 Wed 11:00-12:00>
** Topics
** CLOSED Dissertation Work [3/3]
   CLOSED: [2019-07-26 Fri 18:44] SCHEDULED: <2019-07-26 Fri>
- [X] Take import out of import function, get it to work on char vec instead
- [X] Arrange into package
- [X] Prepare shiny directory
** CLOSED Further Dissertation Work [3/4]
   CLOSED: [2019-08-08 Thu 17:26] SCHEDULED: <2019-08-07 Wed 13:00-17:00>
- [X] Re-read Shiny Documentation
- [X] Test an increment-decrement app
- [ ] Try advanced features (action button, ui hiding etc.)
- [X] Begin work on import functions in shiny
* Meeting Chris
<2019-08-08 Thu 15:00-16:30>*
* CLOSED Dissertation Work [3/3]
   CLOSED: [2019-08-16 Fri 12:28] SCHEDULED: <2019-08-15 Thu>
- [X] Send PDF to Chris of dissertation so far
- [X] Re-build Package; script it for automatic rebuild
- [X] Continue working on interface
* Meeting Chris<2019-08-16 Fri 11:00>
daniel.barnett@auckland.ac.nz
** Dissertation Work [3/3]
- [X] Rewrite to set table as mutating state
- [X] Write for dissertation
- [X] Include documentation in Appendix
** CLOSED Meeting Daniel
   CLOSED: [2019-08-20 Tue 11:02] SCHEDULED: <2019-08-19 Mon 10:00>
* Meeting Chris<2019-08-21 Wed 15:00>
** CLOSED Dissertation Work [1/4]
   CLOSED: [2019-09-17 Tue 11:02] SCHEDULED: <2019-08-22 Thu>
- [X] add insight mutate function
- [ ] add visualisation
- [ ] change to text in csvs
- [ ] Emil Hvidtfeldt - word tree
* Meeting Chris<2019-08-28 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


* Meeting Chris<2019-09-04 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


* Meeting Chris<2019-09-11 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


* Meeting Chris<2019-09-18 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


* Meeting Chris<2019-09-25 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


* Meeting Chris<2019-10-02 Wed 15:00>
** Dissertation Work [0/1]
- [ ]


